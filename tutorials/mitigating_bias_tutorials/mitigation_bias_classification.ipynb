{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model for Binary Classification Problem with Bias Mitigators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from holisticai.pipeline import Pipeline\n",
    "from holisticai.datasets import load_adult\n",
    "from holisticai.bias.metrics import classification_bias_metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "dataset = load_adult()\n",
    "\n",
    "df = pd.concat([dataset[\"data\"], dataset[\"target\"]], axis=1)\n",
    "protected_variables = [\"sex\", \"race\"]\n",
    "output_variable = [\"class\"]\n",
    "\n",
    "favorable_label = 1\n",
    "unfavorable_label = 0\n",
    "\n",
    "y = df[output_variable].replace(\n",
    "    {\">50K\": favorable_label, \"<=50K\": unfavorable_label}\n",
    ")\n",
    "x = pd.get_dummies(df.drop(protected_variables + output_variable, axis=1))\n",
    "group = [\"sex\"]\n",
    "group_a = df[group] == \"Female\"\n",
    "group_b = df[group] == \"Male\"\n",
    "data = [x, y, group_a, group_b]\n",
    "\n",
    "dataset = train_test_split(*data, test_size=0.2, shuffle=True)\n",
    "train_data = dataset[::2]\n",
    "test_data = dataset[1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib,os\n",
    "os.chdir(pathlib.Path(os.path.abspath('')).parent.resolve())\n",
    "\n",
    "from holisticai.datasets import load_adult\n",
    "dataset = load_adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     workclass    fnlwgt     education  education-num  \\\n",
       "0      25.0       Private  226802.0          11th            7.0   \n",
       "1      38.0       Private   89814.0       HS-grad            9.0   \n",
       "2      28.0     Local-gov  336951.0    Assoc-acdm           12.0   \n",
       "3      44.0       Private  160323.0  Some-college           10.0   \n",
       "4      18.0           NaN  103497.0  Some-college           10.0   \n",
       "...     ...           ...       ...           ...            ...   \n",
       "48837  27.0       Private  257302.0    Assoc-acdm           12.0   \n",
       "48838  40.0       Private  154374.0       HS-grad            9.0   \n",
       "48839  58.0       Private  151910.0       HS-grad            9.0   \n",
       "48840  22.0       Private  201490.0       HS-grad            9.0   \n",
       "48841  52.0  Self-emp-inc  287927.0       HS-grad            9.0   \n",
       "\n",
       "           marital-status         occupation relationship   race     sex  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                NaN    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0               0.0           0.0            40.0  United-States  <=50K  \n",
       "1               0.0           0.0            50.0  United-States  <=50K  \n",
       "2               0.0           0.0            40.0  United-States   >50K  \n",
       "3            7688.0           0.0            40.0  United-States   >50K  \n",
       "4               0.0           0.0            30.0  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "48837           0.0           0.0            38.0  United-States  <=50K  \n",
       "48838           0.0           0.0            40.0  United-States   >50K  \n",
       "48839           0.0           0.0            40.0  United-States  <=50K  \n",
       "48840           0.0           0.0            20.0  United-States  <=50K  \n",
       "48841       15024.0           0.0            40.0  United-States   >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = load_adult()\n",
    "df = pd.concat([dataset['data'], dataset['target']], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    :caption: Tutorials , favorable_label, unfavorable_label = load_preprocessed_adult()\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "X, y, group_a, group_b = train_data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "X, y, group_a, group_b = test_data\n",
    "y_pred = pipeline.predict(X)\n",
    "df_baseline = classification_bias_metrics(group_b.to_numpy().ravel(), \n",
    "                            group_a.to_numpy().ravel(), \n",
    "                            y_pred.ravel(), \n",
    "                            y.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate_pipeline(pipeline, data_cls=None):\n",
    "    \n",
    "    if data_cls is None:\n",
    "        train_data , test_data , favorable_label , unfavorable_label = load_preprocessed_adult()\n",
    "    else:\n",
    "        df = data_cls.load_preprocessed_adult_df()\n",
    "        train_data , test_data , favorable_label , unfavorable_label = data_cls.custom_preprocessing(df)\n",
    "    \n",
    "    X, y, group_a, group_b = train_data\n",
    "    fit_params = {\n",
    "        'bm__group_a': group_a,\n",
    "        'bm__group_b': group_b,\n",
    "        'bm__favorable_label': favorable_label,\n",
    "        'bm__unfavorable_label': unfavorable_label,\n",
    "    }\n",
    "    pipeline.fit(X, y, **fit_params)\n",
    "\n",
    "    X, y, group_a, group_b = test_data\n",
    "    predict_params = {\n",
    "        'bm__group_a': group_a,\n",
    "        'bm__group_b': group_b,\n",
    "    }\n",
    "    y_pred = pipeline.predict(X, **predict_params)\n",
    "    df = classification_bias_metrics(group_b.to_numpy().ravel(), \n",
    "                                group_a.to_numpy().ravel(), \n",
    "                                y_pred.ravel(), \n",
    "                                y.to_numpy().ravel())\n",
    "    return df\n",
    "\n",
    "def format_result_colum(name,config):\n",
    "    return config['result'].rename(columns={'Value':name}).iloc[:,0]\n",
    "\n",
    "def show_result_table(configurations, df_baseline):\n",
    "    table = pd.concat([df_baseline.iloc[:,0]] + [format_result_colum(name,config) \n",
    "            for name,config in configurations.items()] + [df_baseline.iloc[:,1]],axis=1)\n",
    "    return table.rename(columns={'Value':'Baseline'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "configurations = defaultdict(dict)\n",
    "\n",
    "from holisticai.bias.mitigation.preprocessing import Reweighing\n",
    "configurations['Reweighing']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_preprocessing', Reweighing()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.preprocessing import DisparateImpactRemover\n",
    "configurations['Disparate Impact Remover']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_preprocessing', DisparateImpactRemover()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.preprocessing import LearningFairRepresentation\n",
    "configurations['Learning Fair Representation']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_preprocessing', LearningFairRepresentation(k=10)),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.preprocessing import OptimPreproc\n",
    "data_cls = Dclass()\n",
    "optim_options = {\n",
    "    \"distortion_fun\": data_cls.get_distortion_adult,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0]\n",
    "}\n",
    "configurations['Optim Preproc']['pipeline'] = Pipeline(steps=[\n",
    "        ('bm_preprocessing', OptimPreproc(optim_options=optim_options)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('estimator', LogisticRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/holisticai_lib/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/holisticai_lib/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/holisticai_lib/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m config_name,config \u001b[39min\u001b[39;00m configurations\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m config_name\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mOptim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         config[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fit_and_evaluate_pipeline(config[\u001b[39m'\u001b[39;49m\u001b[39mpipeline\u001b[39;49m\u001b[39m'\u001b[39;49m], data_cls)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         config[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fit_and_evaluate_pipeline(config[\u001b[39m'\u001b[39m\u001b[39mpipeline\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb Cell 12\u001b[0m in \u001b[0;36mfit_and_evaluate_pipeline\u001b[0;34m(pipeline, data_cls)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     df \u001b[39m=\u001b[39m data_cls\u001b[39m.\u001b[39mload_preprocessed_adult_df()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_data , test_data , favorable_label , unfavorable_label \u001b[39m=\u001b[39m data_cls\u001b[39m.\u001b[39;49mcustom_preprocessing(df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X, y, group_a, group_b \u001b[39m=\u001b[39m train_data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m fit_params \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbm__group_a\u001b[39m\u001b[39m'\u001b[39m: group_a,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbm__group_b\u001b[39m\u001b[39m'\u001b[39m: group_b,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbm__favorable_label\u001b[39m\u001b[39m'\u001b[39m: favorable_label,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbm__unfavorable_label\u001b[39m\u001b[39m'\u001b[39m: unfavorable_label,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/mitigation_bias_classification.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/GitHub2/holisticai/tutorials/mitigating_bias_tutorials/../../holisticai/utils/_tutorial_utils.py:133\u001b[0m, in \u001b[0;36mDclass.custom_preprocessing\u001b[0;34m(self, df, sub_samp, balance)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m\"\"\"The custom pre-processing function is adapted from\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39mhttps://github.com/fair-preprocessing/nips2017/blob/master/Adult/code/Generate_Adult_Data.ipynb\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mIf sub_samp != False, then return smaller version of dataset truncated to tiny_test data points.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# Group age by decade\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mAge (decade)\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mAge\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[39m# df['Age (decade)'] = df['age'].apply(lambda x: np.floor(x/10.0)*10.0)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgroup_edu\u001b[39m(x):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/holisticai_lib/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/holisticai_lib/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "for config_name,config in configurations.items():\n",
    "    if config_name.startswith('Optim'):\n",
    "        config['result'] = fit_and_evaluate_pipeline(config['pipeline'], data_cls)\n",
    "    else:\n",
    "        config['result'] = fit_and_evaluate_pipeline(config['pipeline'])\n",
    "show_result_table(configurations, df_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "configurations = defaultdict(dict)\n",
    "\n",
    "from holisticai.bias.mitigation.postprocessing import EqualizedOdds\n",
    "configurations['Equalized Odds']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ('bm_postprocessing', EqualizedOdds()),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.postprocessing import CalibratedEqualizedOdds\n",
    "configurations['Calibrated Equalized Odds']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ('bm_postprocessing', CalibratedEqualizedOdds()),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.postprocessing import RejectOptionClassification\n",
    "configurations['Reject Option Classification']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ('bm_postprocessing', RejectOptionClassification()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_thresh': 0.21787878787878787, 'roc_margin': 0.12894867037724178, 'balanced_accurracy': 0.7982554875982124, 'fair_metric': 0.04938045535005803}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Equalized Odds</th>\n",
       "      <th>Calibrated Equalized Odds</th>\n",
       "      <th>Reject Option Classification</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>0.142297</td>\n",
       "      <td>0.080455</td>\n",
       "      <td>0.123103</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>2.496410</td>\n",
       "      <td>1.561524</td>\n",
       "      <td>2.282961</td>\n",
       "      <td>1.088769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Fifths Rule</th>\n",
       "      <td>0.400575</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>0.438028</td>\n",
       "      <td>0.918469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohen D</th>\n",
       "      <td>0.367303</td>\n",
       "      <td>0.203408</td>\n",
       "      <td>0.325580</td>\n",
       "      <td>0.056242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equality of Opportunity Difference</th>\n",
       "      <td>0.137864</td>\n",
       "      <td>0.057090</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.191182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Difference</th>\n",
       "      <td>0.046398</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>0.061371</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.092131</td>\n",
       "      <td>0.026646</td>\n",
       "      <td>-0.010981</td>\n",
       "      <td>-0.126445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Difference</th>\n",
       "      <td>-0.069446</td>\n",
       "      <td>-0.044860</td>\n",
       "      <td>-0.144092</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>0.063582</td>\n",
       "      <td>0.135870</td>\n",
       "      <td>-0.162615</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Baseline  Equalized Odds  \\\n",
       "Metric                                                         \n",
       "Statistical Parity                  0.142297        0.080455   \n",
       "Disparate Impact                    2.496410        1.561524   \n",
       "Four Fifths Rule                    0.400575        0.640400   \n",
       "Cohen D                             0.367303        0.203408   \n",
       "Equality of Opportunity Difference  0.137864        0.057090   \n",
       "False Positive Rate Difference      0.046398       -0.003797   \n",
       "Average Odds Difference             0.092131        0.026646   \n",
       "Accuracy Difference                -0.069446       -0.044860   \n",
       "Correlation Difference              0.063582        0.135870   \n",
       "\n",
       "                                    Calibrated Equalized Odds  \\\n",
       "Metric                                                          \n",
       "Statistical Parity                                   0.123103   \n",
       "Disparate Impact                                     2.282961   \n",
       "Four Fifths Rule                                     0.438028   \n",
       "Cohen D                                              0.325580   \n",
       "Equality of Opportunity Difference                  -0.083333   \n",
       "False Positive Rate Difference                       0.061371   \n",
       "Average Odds Difference                             -0.010981   \n",
       "Accuracy Difference                                 -0.144092   \n",
       "Correlation Difference                              -0.162615   \n",
       "\n",
       "                                    Reject Option Classification  Reference  \n",
       "Metric                                                                       \n",
       "Statistical Parity                                      0.026026          0  \n",
       "Disparate Impact                                        1.088769          1  \n",
       "Four Fifths Rule                                        0.918469          1  \n",
       "Cohen D                                                 0.056242          0  \n",
       "Equality of Opportunity Difference                     -0.191182          0  \n",
       "False Positive Rate Difference                         -0.061708          0  \n",
       "Average Odds Difference                                -0.126445          0  \n",
       "Accuracy Difference                                     0.011224          0  \n",
       "Correlation Difference                                  0.070575          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for config_name,config in configurations.items():\n",
    "    config['result'] = fit_and_evaluate_pipeline(config['pipeline'])\n",
    "show_result_table(configurations, df_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "configurations = defaultdict(dict)\n",
    "\n",
    "from holisticai.bias.mitigation.inprocessing import GridSearchReduction\n",
    "\n",
    "model = LogisticRegression()\n",
    "inprocessing_model = GridSearchReduction(constraints=\"DemographicParity\", grid_size=20).transform_estimator(model)\n",
    "\n",
    "configurations['GridSearch Reduction']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_inprocessing', inprocessing_model),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.inprocessing import ExponentiatedGradientReduction\n",
    "\n",
    "model = LogisticRegression()\n",
    "inprocessing_model = ExponentiatedGradientReduction(constraints=\"DemographicParity\").transform_estimator(model)\n",
    "\n",
    "configurations['ExponentiatedGradient Reduction']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_inprocessing', inprocessing_model),\n",
    "    ])\n",
    " \n",
    "from holisticai.bias.mitigation.inprocessing import AdversarialDebiasing\n",
    "\n",
    "inprocessing_model = AdversarialDebiasing(features_dim=X.shape[1], epochs=50, batch_size=64, hidden_size=64, adversary_loss_weight=0.1, verbose=1, \n",
    "                                          use_debias=True).transform_estimator()\n",
    "\n",
    "configurations['Adversarial Debiasing']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_inprocessing', inprocessing_model),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.inprocessing import MetaFairClassifier\n",
    "\n",
    "inprocessing_model = MetaFairClassifier(tau=0.7, type='fdr').transform_estimator()\n",
    "\n",
    "configurations['Meta Fair Classifier']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_inprocessing', inprocessing_model),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.inprocessing import PrejudiceRemover\n",
    "\n",
    "inprocessing_model = PrejudiceRemover().transform_estimator()\n",
    "\n",
    "configurations['Prejudice Remover']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_inprocessing', inprocessing_model),\n",
    "    ])\n",
    "\n",
    "from holisticai.bias.mitigation.inprocessing import GerryFairClassifier\n",
    "\n",
    "inprocessing_model = GerryFairClassifier().transform_estimator()\n",
    "\n",
    "configurations['Gerry Fair Classifier']['pipeline'] = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('bm_inprocessing', inprocessing_model),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[49,   125] loss: 0.314                 adv_loss: 0.619:  98%|█████████▊| 49/50 [00:28<00:00,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>GridSearch Reduction</th>\n",
       "      <th>ExponentiatedGradient Reduction</th>\n",
       "      <th>Adversarial Debiasing</th>\n",
       "      <th>Meta Fair Classifier</th>\n",
       "      <th>Prejudice Remover</th>\n",
       "      <th>Gerry Fair Classifier</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>0.142297</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>0.085059</td>\n",
       "      <td>0.166084</td>\n",
       "      <td>0.096106</td>\n",
       "      <td>0.137614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>2.496410</td>\n",
       "      <td>1.009690</td>\n",
       "      <td>0.936737</td>\n",
       "      <td>1.680473</td>\n",
       "      <td>1.254612</td>\n",
       "      <td>1.878120</td>\n",
       "      <td>2.786232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Fifths Rule</th>\n",
       "      <td>0.400575</td>\n",
       "      <td>0.990403</td>\n",
       "      <td>0.936737</td>\n",
       "      <td>0.595070</td>\n",
       "      <td>0.797059</td>\n",
       "      <td>0.532447</td>\n",
       "      <td>0.358908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohen D</th>\n",
       "      <td>0.367303</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>0.221386</td>\n",
       "      <td>0.397105</td>\n",
       "      <td>0.255620</td>\n",
       "      <td>0.371841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equality of Opportunity Difference</th>\n",
       "      <td>0.137864</td>\n",
       "      <td>-0.294304</td>\n",
       "      <td>-0.260343</td>\n",
       "      <td>-0.193632</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>-0.042496</td>\n",
       "      <td>0.049297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Difference</th>\n",
       "      <td>0.046398</td>\n",
       "      <td>-0.035462</td>\n",
       "      <td>-0.059264</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.138874</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.060136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.092131</td>\n",
       "      <td>-0.164883</td>\n",
       "      <td>-0.159803</td>\n",
       "      <td>-0.084878</td>\n",
       "      <td>0.076051</td>\n",
       "      <td>-0.015455</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Difference</th>\n",
       "      <td>-0.069446</td>\n",
       "      <td>-0.087594</td>\n",
       "      <td>-0.066764</td>\n",
       "      <td>-0.114727</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>-0.096846</td>\n",
       "      <td>-0.118868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlation Difference</th>\n",
       "      <td>0.063582</td>\n",
       "      <td>-0.090189</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>-0.139514</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.015484</td>\n",
       "      <td>-0.043093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Baseline  GridSearch Reduction  \\\n",
       "Metric                                                               \n",
       "Statistical Parity                  0.142297              0.001574   \n",
       "Disparate Impact                    2.496410              1.009690   \n",
       "Four Fifths Rule                    0.400575              0.990403   \n",
       "Cohen D                             0.367303              0.004256   \n",
       "Equality of Opportunity Difference  0.137864             -0.294304   \n",
       "False Positive Rate Difference      0.046398             -0.035462   \n",
       "Average Odds Difference             0.092131             -0.164883   \n",
       "Accuracy Difference                -0.069446             -0.087594   \n",
       "Correlation Difference              0.063582             -0.090189   \n",
       "\n",
       "                                    ExponentiatedGradient Reduction  \\\n",
       "Metric                                                                \n",
       "Statistical Parity                                        -0.009969   \n",
       "Disparate Impact                                           0.936737   \n",
       "Four Fifths Rule                                           0.936737   \n",
       "Cohen D                                                   -0.027846   \n",
       "Equality of Opportunity Difference                        -0.260343   \n",
       "False Positive Rate Difference                            -0.059264   \n",
       "Average Odds Difference                                   -0.159803   \n",
       "Accuracy Difference                                       -0.066764   \n",
       "Correlation Difference                                    -0.002041   \n",
       "\n",
       "                                    Adversarial Debiasing  \\\n",
       "Metric                                                      \n",
       "Statistical Parity                               0.085059   \n",
       "Disparate Impact                                 1.680473   \n",
       "Four Fifths Rule                                 0.595070   \n",
       "Cohen D                                          0.221386   \n",
       "Equality of Opportunity Difference              -0.193632   \n",
       "False Positive Rate Difference                   0.023876   \n",
       "Average Odds Difference                         -0.084878   \n",
       "Accuracy Difference                             -0.114727   \n",
       "Correlation Difference                          -0.139514   \n",
       "\n",
       "                                    Meta Fair Classifier  Prejudice Remover  \\\n",
       "Metric                                                                        \n",
       "Statistical Parity                              0.166084           0.096106   \n",
       "Disparate Impact                                1.254612           1.878120   \n",
       "Four Fifths Rule                                0.797059           0.532447   \n",
       "Cohen D                                         0.397105           0.255620   \n",
       "Equality of Opportunity Difference              0.013227          -0.042496   \n",
       "False Positive Rate Difference                  0.138874           0.011586   \n",
       "Average Odds Difference                         0.076051          -0.015455   \n",
       "Accuracy Difference                             0.007264          -0.096846   \n",
       "Correlation Difference                          0.037146           0.015484   \n",
       "\n",
       "                                    Gerry Fair Classifier  Reference  \n",
       "Metric                                                                \n",
       "Statistical Parity                               0.137614          0  \n",
       "Disparate Impact                                 2.786232          1  \n",
       "Four Fifths Rule                                 0.358908          1  \n",
       "Cohen D                                          0.371841          0  \n",
       "Equality of Opportunity Difference               0.049297          0  \n",
       "False Positive Rate Difference                   0.060136          0  \n",
       "Average Odds Difference                          0.054717          0  \n",
       "Accuracy Difference                             -0.118868          0  \n",
       "Correlation Difference                          -0.043093          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for config_name,config in configurations.items():\n",
    "    config['result'] = fit_and_evaluate_pipeline(config['pipeline'])\n",
    "show_result_table(configurations, df_baseline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
